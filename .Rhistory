review_score_time_info <- review_score_time_info %>%
mutate(year = substr(temp_time$V1,1,4),
month = substr(temp_time$V1,6,7),
day = substr(temp_time$V1,9,10),
day = substr(temp_time$V1,9,10),
hour = substr(temp_time$V2,1,2),
) %>%
select(-time)
# factor -> numeric
review_score_time_info$score <- as.numeric(review_score_time_info$score)
review_score_time_info$year <- as.numeric(review_score_time_info$year)
review_score_time_info$month <- as.numeric(review_score_time_info$month)
review_score_time_info$day <- as.numeric(review_score_time_info$day)
review_score_time_info$hour <- as.numeric(review_score_time_info$hour)
review_score_time_info <- review_score_time_info[-20017]
# 데이터 시간별 컬럼 추가
review_score_time_info <- MovieInfo_Titanic
temp_time <- as.data.frame(t(data.frame(str_split(review_score_time_info$time, pattern = ' '))))
review_score_time_info <- review_score_time_info %>%
mutate(year = substr(temp_time$V1,1,4),
month = substr(temp_time$V1,6,7),
day = substr(temp_time$V1,9,10),
day = substr(temp_time$V1,9,10),
hour = substr(temp_time$V2,1,2),
) %>%
select(-time)
# factor -> numeric
review_score_time_info$score <- as.numeric(review_score_time_info$score)
review_score_time_info$year <- as.numeric(review_score_time_info$year)
review_score_time_info$month <- as.numeric(review_score_time_info$month)
review_score_time_info$day <- as.numeric(review_score_time_info$day)
review_score_time_info$hour <- as.numeric(review_score_time_info$hour)
review_score_time_info[20017]
View(review_score_time_info)
review_score_time_info <- review_score_time_info[-20017]
# 데이터 시간별 컬럼 추가
review_score_time_info <- MovieInfo_Titanic
review_score_time_info <- review_score_time_info[-20017]
review_score_time_info <- review_score_time_info[-20017,,]
temp_time <- as.data.frame(t(data.frame(str_split(review_score_time_info$time, pattern = ' '))))
review_score_time_info <- review_score_time_info %>%
mutate(year = substr(temp_time$V1,1,4),
month = substr(temp_time$V1,6,7),
day = substr(temp_time$V1,9,10),
day = substr(temp_time$V1,9,10),
hour = substr(temp_time$V2,1,2),
) %>%
select(-time)
# factor -> numeric
review_score_time_info$score <- as.numeric(review_score_time_info$score)
review_score_time_info$year <- as.numeric(review_score_time_info$year)
review_score_time_info$month <- as.numeric(review_score_time_info$month)
review_score_time_info$day <- as.numeric(review_score_time_info$day)
review_score_time_info$hour <- as.numeric(review_score_time_info$hour)
review_score_time_info <- review_score_time_info[-20017]
review_score <- review_score_time_info %>% filter(score <= 3)
reple_Noun <- review_score$text
reple_Noun <- sapply(reple_Noun, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_replace<- str_replace_all(reple_unlist, "[^[:alpha:]]","")
reple_filter1<- Filter(function(x) {nchar(x) <= 10}, reple_replace)
reple_filter2<- Filter(function(x) {nchar(x) >= 2}, reple_filter1)
head(sort(table(reple_filter2),decreasing = T),100)
wordcloudRepleTxt <-as.data.frame(sort(table(reple_filter2), decreasing = T))
wordcloudRepleTxt2 <- wordcloudRepleTxt %>% filter(wordcloudRepleTxt$reple_filter2 != '영화')
head(wordcloudRepleTxt2)
wordcloud2(wordcloudRepleTxt2, maxRotation = -pi/36,  minSize = 2, rotateRatio = 1,  color = "random-light", backgroundColor = "grey")
head(sort(table(wordcloudRepleTxt2),decreasing = T), 10)
head(sort(table(wordcloudRepleTxt2),decreasing = T), 10)
head(sort(table(wordcloudRepleTxt2), decreasing = T), 10)
View(word)
View(wordcloudRepleTxt2)
head(sort(wordcloudRepleTxt2, decreasing = T), 10)
head(wordcloudRepleTxt2, 10)
sort(table(reple_filter2), decreasing = T)
head(wordcloudRepleTxt2, 12)
head(wordcloudRepleTxt2, 15)
head(wordcloudRepleTxt2, 20)
head(wordcloudRepleTxt2, 30)
head(wordcloudRepleTxt2, 21)
head(wordcloudRepleTxt2, 21)
review_time <- review_score_time_info %>% filter(year == 2013 & month == 3 & day == 19)
View(review_time)
review_score_summary <- review_score %>% group_by(year, month, day) %>% summarise(meanScore = mean(score))
review_score_summary
View(review_score_summary)
review_score_summary <- review_score %>% group_by(year, month, day) %>% summarise(meanScore = mean(score), count = n())
View(review_score_summary)
review_score_summary <- review_score %>% group_by(year, month, day) %>% summarise(meanScore = mean(score), count = n()) %>% order(meanScore, desc) %>% head()
review_score_summary <- review_score %>% group_by(year, month, day) %>% summarise(meanScore = mean(score), count = n()) %>% order(meanScore, desc) %>% head()
review_score_summary <- review_score %>% group_by(year, month, day) %>% summarise(meanScore = mean(score), count = n()) %>% order(count, desc) %>% head()
review_score_summary <- review_score %>% group_by(year, month, day) %>% summarise(meanScore = mean(score), count = n()) %>% order(count, desc) %>% head()
review_score_summary <- review_score %>%
group_by(year, month, day) %>%
summarise(meanScore = mean(score), count = n()) %>%
order_by(count, desc) %>% head()
review_score_summary <- review_score %>%
group_by(year, month, day) %>%
summarise(meanScore = mean(score), count = n()) %>%
arrange(count, desc) %>% head()
review_score_summary <- review_score %>%
group_by(year, month, day) %>%
summarise(meanScore = mean(score), count = n()) %>%
arrange(count) %>% head()
View(review_score_summary)
review_score_summary <- review_score %>%
group_by(year, month, day) %>%
summarise(meanScore = mean(score), count = n()) %>%
arrange(desc(count)) %>% head()
View(review_score_summary)
review_score_summary
review_score_summary <- review_score %>%
group_by(year, month, day) %>%
summarise(meanScore = mean(score), count = n()) %>%
arrange(desc(count)) %>% head(10)
review_score_summary
review_time <- review_score_time_info %>% filter(year == 2013 & month == 3 & day == c(19:25))
review_time <- review_score_time_info %>% filter(year == 2013 & month == 3 & day %in% c(19:25))
View(review_time)
review_time <- review_score_time_info %>% filter(year == 2013 & month == 3 & day %in% c(19:25))
# 그 날짜의 리뷰 분석
review_time <- review_score_time_info %>% filter(year == 2013 & month == 3 & day %in% c(19:25))
reple_Noun <- review_time$text
reple_Noun <- sapply(reple_Noun, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_replace<- str_replace_all(reple_unlist, "[^[:alpha:]]","")
reple_filter1<- Filter(function(x) {nchar(x) <= 10}, reple_replace)
reple_filter2<- Filter(function(x) {nchar(x) >= 2}, reple_filter1)
sort(table(reple_filter2), decreasing = T)
wordcloudRepleTxt <-as.data.frame(sort(table(reple_filter2), decreasing = T))
wordcloudRepleTxt2 <- wordcloudRepleTxt %>% filter(wordcloudRepleTxt$reple_filter2 != '영화')
wordcloud2(wordcloudRepleTxt2, maxRotation = -pi/36,  minSize = 2, rotateRatio = 1,  color = "random-light", backgroundColor = "grey")
head(wordcloudRepleTxt2, 21)
head(wordcloudRepleTxt2, 20)
library(XML)
library(stringr)
library(rvest)
library(dplyr)
library(reshape2)
library(rJava)
library(tm)
library(KoNLP)
library(wordcloud2)
library(xlsx)
library(readxl)
library(ggplot2)
library(gridExtra)
wordcloud2(wordcloudRepleTxt2, maxRotation = -pi/36,  minSize = 2, rotateRatio = 1,  color = "random-light", backgroundColor = "grey")
wordcloud2(wordcloudRepleTxt2, maxRotation = -pi/36,  minSize = 2, rotateRatio = 1,  color = "random-light", backgroundColor = "grey")
library(XML)
library(stringr)
library(rvest)
library(dplyr)
library(reshape2)
library(rJava)
library(tm)
library(KoNLP)
library(wordcloud2)
library(xlsx)
library(readxl)
library(ggplot2)
library(gridExtra)
useSejongDic()
wordcloud2(wordcloudRepleTxt2, maxRotation = -pi/36,  minSize = 2, rotateRatio = 1,  color = "random-light", backgroundColor = "grey")
library(wordcloud2)
wordcloud2(demoFreq)
knitr::opts_chunk$set(echo = TRUE)
library(wordcloud2)
library(XML)
library(stringr)
library(rvest)
library(dplyr)
library(reshape2)
library(rJava)
library(tm)
library(KoNLP)
library(wordcloud2)
library(xlsx)
library(readxl)
library(ggplot2)
library(gridExtra)
useSejongDic()
wordcloudRepleTxt2 <- wordcloudRepleTxt %>% filter(wordcloudRepleTxt$reple_filter2 != '영화')
library(XML)
library(stringr)
library(rvest)
library(dplyr)
library(reshape2)
library(rJava)
library(tm)
library(KoNLP)
library(wordcloud2)
library(xlsx)
library(readxl)
library(ggplot2)
library(gridExtra)
useSejongDic()
# 그래프의 이상치에 대한 분석
# 데이터 시간별 컬럼 추가
review_score_time_info <- MovieInfo_Titanic
# 분석이 안되는 이상치 제거
review_score_time_info <- review_score_time_info[-20017,,]
temp_time <- as.data.frame(t(data.frame(str_split(review_score_time_info$time, pattern = ' '))))
review_score_time_info <- review_score_time_info %>%
mutate(year = substr(temp_time$V1,1,4),
month = substr(temp_time$V1,6,7),
day = substr(temp_time$V1,9,10),
day = substr(temp_time$V1,9,10),
hour = substr(temp_time$V2,1,2),
) %>%
select(-time)
# factor -> numeric
review_score_time_info$score <- as.numeric(review_score_time_info$score)
review_score_time_info$year <- as.numeric(review_score_time_info$year)
review_score_time_info$month <- as.numeric(review_score_time_info$month)
review_score_time_info$day <- as.numeric(review_score_time_info$day)
review_score_time_info$hour <- as.numeric(review_score_time_info$hour)
# 평점 3점 이하에 대한 분석
review_score <- review_score_time_info %>% filter(score <= 3)
# 이상치 필터링
review_score_summary <- review_score %>%
group_by(year, month, day) %>%
summarise(meanScore = mean(score), count = n()) %>%
arrange(desc(count)) %>% head(10)
# 이상치가 포함된 날짜 확인
review_score_summary
# 해당 날짜의 리뷰 분석
review_time <- review_score_time_info %>% filter(year == 2013 & month == 3 & day %in% c(19:25))
reple_Noun <- review_time$text
reple_Noun <- sapply(reple_Noun, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_replace<- str_replace_all(reple_unlist, "[^[:alpha:]]","")
reple_filter1<- Filter(function(x) {nchar(x) <= 10}, reple_replace)
reple_filter2<- Filter(function(x) {nchar(x) >= 2}, reple_filter1)
wordcloudRepleTxt <-as.data.frame(sort(table(reple_filter2), decreasing = T))
wordcloudRepleTxt2 <- wordcloudRepleTxt %>% filter(wordcloudRepleTxt$reple_filter2 != '영화')
wordcloudRepleTxt2
wordcloudRepleTxt2 <- wordcloudRepleTxt %>% filter(wordcloudRepleTxt$reple_filter2 != '영화') %>% head(10)
wordcloudRepleTxt2
wordcloudRepleTxt2 <- wordcloudRepleTxt %>% filter(wordcloudRepleTxt$reple_filter2 != '영화') %>% head(15)
wordcloudRepleTxt2()
wordcloudRepleTxt2
wordcloudRepleTxt2 <- wordcloudRepleTxt %>% filter(wordcloudRepleTxt$reple_filter2 != '영화') %>% head(10)
wordcloudRepleTxt2
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reple_filter2 )) +geom_point()
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, -Freq )) +geom_point()
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, -Freq))) +geom_point()
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, -Freq))) +geom_point()
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, -Freq))) +geom_point()
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +geom_point()
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) + geom_point()
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) + geom_point() +
geom_segment(aes(yend = reple_filter2), xend = 0, color = "grey50") + geom_point(size = 3, aes(color = Freq))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) + geom_point(size = 5) +
geom_segment(aes(yend = reple_filter2), xend = 0, color = "grey50") + geom_point(size = 3, aes(color = Freq))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq)) +
geom_segment(aes(yend = reple_filter2), xend = 0, color = "grey50") + geom_point(size = 5, aes(color = Freq))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2), xend = 0, color = "grey50") + geom_point(size = 5, aes(color = Freq))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2), xend = 0, color = "grey50") + geom_point(size = 5, aes(color = Freq))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2), xend = 0, color = "grey50", size = 3) + geom_point(size = 5, aes(color = Freq))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2), xend = 0, color = Freq, size = 3) + geom_point(size = 5, aes(color = Freq))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2), xend = 0, color = Freq, size = 3) + geom_point(size = 5, aes(color = Freq))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2, color = Freq,), xend = 0, size = 3) + geom_point(size = 5, aes(color = Freq))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2, color = Freq,), xend = 0, size = 3) + geom_point(size = 10, aes(color = Freq))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2, color = Freq,), xend = 0, size = 3) + geom_point(size = 7, aes(color = Freq))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2, color = Freq,), xend = 0, size = 3) + geom_point(size = 7, aes(color = Freq)) + theme_minimal()
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2, color = Freq,), xend = 0, size = 3) + geom_point(size = 7, aes(color = Freq)) + theme_minimal() +
theme(axis.text.y = element_text(face = 'bold', size = 15))
wordcloudRepleTxt2
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2, color = Freq,), xend = 0, size = 3) + geom_point(size = 7, aes(color = Freq)) + theme_minimal() +
theme(axis.text.y = element_text(face = 'bold', size = 15, angle = 15))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2, color = Freq,), xend = 0, size = 3) + geom_point(size = 7, aes(color = Freq)) + theme_minimal() +
theme(axis.text = element_text(face = 'bold', size = 15, angle = 15))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2, color = Freq,), xend = 0, size = 3) + geom_point(size = 7, aes(color = Freq)) + theme_minimal() +
theme(axis.text = element_text(face = 'bold', size = 15, angle = 15)) +
ggtitle('2019년 3월 19일 ~ 25일의 단어 빈도 그래프')
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2, color = Freq,), xend = 0, size = 3) + geom_point(size = 7, aes(color = Freq)) + theme_minimal() +
theme(axis.text = element_text(face = 'bold', size = 15, angle = 15)) +
ggtitle('2019년 3월 19일 ~ 25일의 단어 빈도 그래프') +
theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 20, color = "darkblue"),
theme(axis.text.y = element_text(angle = 90)))
theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 20, color = "darkblue")
theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 20, color = "darkblue")
theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 20, color = "darkblue")
theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 20, color = "darkblue")
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2, color = Freq,), xend = 0, size = 3) + geom_point(size = 7, aes(color = Freq)) + theme_minimal() +
theme(axis.text = element_text(face = 'bold', size = 15, angle = 15)) +
ggtitle('2019년 3월 19일 ~ 25일의 단어 빈도 그래프') +
theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 20, color = "darkblue"))
ggplot(data = wordcloudRepleTxt2, mapping = aes(x = Freq, y = reorder(reple_filter2, Freq))) +
geom_segment(aes(yend = reple_filter2, color = Freq,), xend = 0, size = 3) + geom_point(size = 7, aes(color = Freq)) + theme_minimal() +
theme(axis.text = element_text(face = 'bold', size = 15, angle = 15)) +
ggtitle('2019년 3월 19일 ~ 25일의 단어 빈도 그래프') +
theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 20))
# 파일 읽기
MovieInfo_Titanic <- read_excel(path = "D:/workspace/R_Statistics/MovieInfo_Titanic.xlsx")
# 리뷰 데이터만 추출
reple_wordcloud <- MovieInfo_Titanic$text
# 이상치가 포함된 데이터 제거
reple_wordcloud <- reple_wordcloud[-20017]
# 데이터 필터링
reple_Noun <- sapply(reple_wordcloud, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_replace<- str_replace_all(reple_unlist, "[^[:alpha:]]","")
reple_filter1<- Filter(function(x) {nchar(x) <= 10}, reple_replace)
reple_filter2<- Filter(function(x) {nchar(x) >= 2}, reple_filter1)
head(sort(table(reple_filter2),decreasing = T),100)
# 데이터 출력
wordcloudRepleTxt <-as.data.frame(sort(table(reple_filter2), decreasing = T))
wordcloudRepleTxt2 <- wordcloudRepleTxt %>% filter(wordcloudRepleTxt$reple_filter2 != '영화')
head(wordcloudRepleTxt2)
# 과도한 단어 비율에 대한 정제
for( i in 1:5){
wordcloudRepleTxt2[i,2] <- (i * -200) + 2200
}
# wordcloud2 출력력
wordcloud2(wordcloudRepleTxt2, maxRotation = -pi/36,  minSize = 2, rotateRatio = 1,  color = "random-light", backgroundColor = "grey")
# 데이터 시간별 컬럼 추가
score_time_info <- MovieInfo_Titanic %>% select(-text)
temp_time <- as.data.frame(t(data.frame(str_split(score_time_info$time, pattern = ' '))))
score_time_info <- score_time_info %>%
mutate(year = substr(temp_time$V1,1,4),
month = substr(temp_time$V1,6,7),
day = substr(temp_time$V1,9,10),
day = substr(temp_time$V1,9,10),
hour = substr(temp_time$V2,1,2),
) %>%
select(-time)
# factor -> numeric
score_time_info$score <- as.numeric(score_time_info$score)
score_time_info$year <- as.numeric(score_time_info$year)
score_time_info$month <- as.numeric(score_time_info$month)
score_time_info$day <- as.numeric(score_time_info$day)
score_time_info$hour <- as.numeric(score_time_info$hour)
# 각 시간별 평균 평점 계산
score_year_data <- score_time_info %>% group_by(year) %>% summarise(meanScore = mean(score))
score_month_data <- score_time_info %>% group_by(month) %>% summarise(meanScore = mean(score))
score_day_data <- score_time_info %>% group_by(day) %>% summarise(meanScore = mean(score))
score_hour_data <- score_time_info %>% group_by(hour) %>% summarise(meanScore = mean(score))
# 그래프 그리기 - year
year_plot <- ggplot(data = score_year_data, mapping = aes(x = year, y = meanScore, color = meanScore, group = 1)) + geom_line(size =1) +geom_point(size = 2) +
scale_x_continuous(breaks = seq(2003,2019,2)) + scale_y_continuous(limits = c(7,10)) +
ggtitle('년도별 평점 변동 그래프') +
theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 20, color = "darkblue"),
axis.text.x = element_text(angle = 90)); year_plot
# 그래프 그리기 - month
month_plot <- ggplot(data = score_month_data, mapping = aes(x = month, y = meanScore, color = meanScore, group = 1)) + geom_line(size =1) +geom_point(size = 2) +
scale_x_continuous(breaks = c(1:12)) + scale_y_continuous(limits = c(7,10)) +
ggtitle('월별 평점 변동 그래프') +
theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 20, color = "darkblue"),
theme(axis.text.y = element_text(angle = 90)))
month_plot
# 그래프 그리기 - day
day_plot <- ggplot(data = score_day_data, mapping = aes(x = day, y = meanScore, color = meanScore, group = 1)) + geom_line(size =1) +geom_point(size = 2) +
scale_x_continuous(breaks = seq(1,31,5)) + scale_y_continuous(limits = c(6.5,10)) +
ggtitle('일별 평점 변동 그래프') +
theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 20, color = "darkblue"))
# 그래프 그리기 - hour
hour_plot <- ggplot(data = score_hour_data, mapping = aes(x = hour, y = meanScore, color = meanScore, group = 1)) + geom_line(size =1) +geom_point(size = 2) +
scale_x_continuous(breaks = seq(1,31,5)) + scale_y_continuous(limits = c(8, 10)) +
ggtitle('시간별 평점 변동 그래프') +
theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 20, color = "darkblue"))
# 모든 그래프 출력
grid.arrange(year_plot, month_plot, ncol = 2)
grid.arrange(day_plot, hour_plot, ncol = 2)
# 모든 그래프 출력
grid.arrange(year_plot, month_plot, nrow = 2)
grid.arrange(day_plot, hour_plot, nrow = 2)
library(stringr)
library(dplyr)
library(reshape2)
library(rJava)
library(tm)
library(KoNLP)
library(wordcloud2)
library(readxl)
useSejongDic()
test <- read.csv('d:/Workspace/R_Statistics/data/reply1.csv')
test$x <- as.character(test$x)
test100 <- head(test, 200)
test100
reple_Noun <- sapply(test100, extractNoun, USE.NAMES = F)
View(reple_Noun)
View(reple_Noun)
test100 <- head(test, 100)
test100
reple_Noun <- sapply(test100, extractNoun, USE.NAMES = F)
View(reple_Noun)
View(reple_Noun)
View(reple_Noun)
test <- read.csv('d:/Workspace/R_Statistics/data/reply1.csv')
test$x <- as.character(test$x)
View(head(test))
test10 <- head(test, 10)
test101
test10
reple_Noun <- sapply(test10, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_unlist
test200 <- head(test, 200)
test200
reple_Noun <- sapply(test200, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_unlist
test200 <- head(test, 500)
reple_Noun <- sapply(test500, extractNoun, USE.NAMES = F)
reple_Noun <- sapply(test200, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_unlist
test200 <- head(test, 1000)
reple_Noun <- sapply(test200, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
test200 <- head(test, 10000)
reple_Noun <- sapply(test200, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_unlist
test <- read.csv('d:/Workspace/R_Statistics/data/reply1.csv', stringsAsFactors = T)
test <- read.csv('d:/Workspace/R_Statistics/data/reply1.csv', stringsAsFactors = F)
str(test)
test <- read.csv('d:/Workspace/R_Statistics/data/reply1.csv', stringsAsFactors = F)
test200 <- head(test, 2000)
reple_Noun <- sapply(test200, extractNoun, USE.NAMES = F)
testUnlist <- unlist(test)
head(testUnlist)
str(test)
test200 <- head(testUnlist, 200)
reple_Noun <- sapply(test200, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_unlist
test2 <- test[1:100,]
class(test2)
typeof(test2)
reple_Noun <- sapply(test2, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_unlist
test2 <- test[1:100,]
test2
str(test2)
test2 <- head(test, 100)
str(test2)
reple_Noun <- sapply(test2, extractNoun, USE.NAMES = F)
test <- read.csv('d:/Workspace/R_Statistics/data/reply1.csv', stringsAsFactors = F)
test2 <- head(test, 100)
reple_Noun <- sapply(test2, extractNoun, USE.NAMES = F)
test <- read.csv('d:/Workspace/R_Statistics/data/reply1.csv')
test2 <- as.character(test$x)
test200 <- head(test2,200)
reple_Noun <- sapply(test200, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_unlist
test <- read.csv('d:/Workspace/R_Statistics/data/reply1.csv')
str(test)
test <- read.csv('d:/Workspace/R_Statistics/data/reply1.csv')
test2 <- as.character(test$x)
test200 <- head(test2,200)
reple_Noun <- sapply(test200, extractNoun, USE.NAMES = F)
library(rJava)
library(tm)
library(KoNLP)
library(wordcloud2)
useSejongDic()
reple_Noun <- sapply(test200, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_unlist
test200 <- head(test2,10000)
reple_Noun <- sapply(test200, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_replace<- str_replace_all(reple_unlist, "[^[:alpha:]]","")
reple_filter1<- Filter(function(x) {nchar(x) <= 10}, reple_replace)
reple_filter2<- Filter(function(x) {nchar(x) >= 2}, reple_filter1)
head(sort(table(reple_filter2),decreasing = T),100)
library(stringr)
library(reshape2)
library(rJava)
reple_replace<- str_replace_all(reple_unlist, "[^[:alpha:]]","")
reple_filter1<- Filter(function(x) {nchar(x) <= 10}, reple_replace)
reple_filter2<- Filter(function(x) {nchar(x) >= 2}, reple_filter1)
head(sort(table(reple_filter2),decreasing = T),100)
library(stringr)
library(rJava)
library(tm)
library(KoNLP)
library(wordcloud2)
test <- read.csv('d:/Workspace/R_Statistics/data/reply1.csv')
test2 <- as.character(test$x)
reple_Noun <- sapply(test2, extractNoun, USE.NAMES = F)
reple_unlist <- unlist(reple_Noun)
reple_replace<- str_replace_all(reple_unlist, "[^[:alpha:]]","")
reple_filter1<- Filter(function(x) {nchar(x) <= 10}, reple_replace)
reple_filter2<- Filter(function(x) {nchar(x) >= 2}, reple_filter1)
head(sort(table(reple_filter2),decreasing = T),100)
library(wordcloud2)
aaa <- head(sort(table(reple_filter2),decreasing = T))
wordcloud2(aaa)
aaa <- sort(table(reple_filter2),decreasing = T)
wordcloud2(aaa)
wordcloud2(aaa)
